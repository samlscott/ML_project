\documentclass[11pt,preprint, authoryear]{elsarticle}

\usepackage{lmodern}
%%%% My spacing
\usepackage{setspace}
\setstretch{1.2}
\DeclareMathSizes{12}{14}{10}{10}

% Wrap around which gives all figures included the [H] command, or places it "here". This can be tedious to code in Rmarkdown.
\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

\let\origtable\table
\let\endorigtable\endtable
\renewenvironment{table}[1][2] {
    \expandafter\origtable\expandafter[H]
} {
    \endorigtable
}


\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\def\bibsection{\section*{References}} %%% Make "References" appear before bibliography


\usepackage[round]{natbib}

\usepackage{longtable}
\usepackage[margin=2.3cm,bottom=2cm,top=2.5cm, includefoot]{geometry}
\usepackage{fancyhdr}
\usepackage[bottom, hang, flushmargin]{footmisc}
\usepackage{graphicx}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1.3ex plus 0.5ex minus 0.3ex}
\usepackage{textcomp}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.3pt}

\usepackage{array}
\newcolumntype{x}[1]{>{\centering\arraybackslash\hspace{0pt}}p{#1}}

%%%%  Remove the "preprint submitted to" part. Don't worry about this either, it just looks better without it:
\makeatletter
\def\ps@pprintTitle{%
  \let\@oddhead\@empty
  \let\@evenhead\@empty
  \let\@oddfoot\@empty
  \let\@evenfoot\@oddfoot
}
\makeatother

 \def\tightlist{} % This allows for subbullets!

\usepackage{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=blue,
            pdfborder={0 0 0}}


% The following packages allow huxtable to work:
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{calc}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{caption}


\newenvironment{columns}[1][]{}{}

\newenvironment{column}[1]{\begin{minipage}{#1}\ignorespaces}{%
\end{minipage}
\ifhmode\unskip\fi
\aftergroup\useignorespacesandallpars}

\def\useignorespacesandallpars#1\ignorespaces\fi{%
#1\fi\ignorespacesandallpars}

\makeatletter
\def\ignorespacesandallpars{%
  \@ifnextchar\par
    {\expandafter\ignorespacesandallpars\@gobble}%
    {}%
}
\makeatother

\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{CSLReferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}


\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

%%% Include extra packages specified by user

%%% Hard setting column skips for reports - this ensures greater consistency and control over the length settings in the document.
%% page layout
%% paragraphs
\setlength{\baselineskip}{12pt plus 0pt minus 0pt}
\setlength{\parskip}{12pt plus 0pt minus 0pt}
\setlength{\parindent}{0pt plus 0pt minus 0pt}
%% floats
\setlength{\floatsep}{12pt plus 0 pt minus 0pt}
\setlength{\textfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\intextsep}{14pt plus 0pt minus 0pt}
\setlength{\dbltextfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\dblfloatsep}{14pt plus 0pt minus 0pt}
%% maths
\setlength{\abovedisplayskip}{12pt plus 0pt minus 0pt}
\setlength{\belowdisplayskip}{12pt plus 0pt minus 0pt}
%% lists
\setlength{\topsep}{10pt plus 0pt minus 0pt}
\setlength{\partopsep}{3pt plus 0pt minus 0pt}
\setlength{\itemsep}{5pt plus 0pt minus 0pt}
\setlength{\labelsep}{8mm plus 0mm minus 0mm}
\setlength{\parsep}{\the\parskip}
\setlength{\listparindent}{\the\parindent}
%% verbatim
\setlength{\fboxsep}{5pt plus 0pt minus 0pt}



\begin{document}



\begin{frontmatter}  %

\title{Data Science: Machine Learning}

% Set to FALSE if wanting to remove title (for submission)




\author[Add1]{Samantha Scott}
\ead{20945043@sun.ac.za}





\address[Add1]{Stellenbosch University, Cape Town, South Africa}



\vspace{1cm}


\begin{keyword}
\footnotesize{
Machine Learning \sep Heart Disease Prediction \sep Random Forests \\
\vspace{0.3cm}
}
\end{keyword}



\vspace{0.5cm}

\end{frontmatter}


\newpage
\renewcommand{\contentsname}{Table of Contents}
{\tableofcontents}
\newpage

%________________________
% Header and Footers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}
\chead{}
\rhead{Predicting Heart Disease}
\lfoot{}
\rfoot{\footnotesize Page \thepage}
\lhead{}
%\rfoot{\footnotesize Page \thepage } % "e.g. Page 2"
\cfoot{}

%\setlength\headheight{30pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%________________________

\headsep 35pt % So that header does not go over title




\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

As Boehmke and Greenwell (2020) state, the machine learning process is
very iterative and heuristic-based. It is difficult to establish which
machine learning method would perform best as a predictive tool, with
minimal knowledge of the problem or data at hand. This dilemma is known
as the no free lunch theorem. The aim of this paper is to predict heart
disease amongst patients, using the performing predictive tool.

The investigation consists of a comparison between two machine learning
algorithms, namely Random Forests (RFs) and Support Vector Machines
(SVMs), as prediction tools. In order to assess the predictive powers of
the aforementioned methods, data on possible heart disease patients is
used. The process of using machine learning algorithms to predict heart
disease amongst patients has been broadly explored and this
investigation serves to contribute to this body of literature.
Ultimately, the results of this paper indicate that both RFs as well as
SVMs showcase strong predictive powers, with a classification accuracy
of above 70\%. Further, the models do not gain predictive power once
being fine tuned, indicating that the basic model is sufficient enough,
given the data and problem.

The paper is structured as follows: section 2 provides an overview of
the research question as well the data used to solve the problem at
hand, section 3 provides information on the the methodology followed
when generating the RF and SVM models, section 4 presents and discusses
the results of the models, section 5 highlights the robustness checks
implemented to verify the outcomes of the models, and lastly, section 6
contains the concluding remarks of the paper.

\hypertarget{research-question-and-data}{%
\section{Research Question and Data}\label{research-question-and-data}}

The main goal of the machine learning process is to find an algorithm
that most accurately predicts future values based on a set of features.
This paper aims to establish which machine learning algorithm performs
best when predicting whether a patient has heart disease, or not. The
problem at hand is expressed as a supervised binomial classification
problem. The data used in this investigation is heart disease data from
Kaggle and contains 180 observations. Kaggle is an online platform where
data scientists and machine learning practitioners can access datasets
as well as build portfolios. The benefit of obtaining data from this
source is the usability score assigned to the dataset. This particular
dataset is assigned a higher usability score.

The data used contains a number of health related indicators. For this
investigation, the dependent variable is the presence of heart disease
in a patient. This variable is a binomial, yes or no, variable. Using
other indicators, such as age, whether a patient has a blood disorder
called thalassemia as well as the type of chest pain a patient is
experiencing, models are generated to predict if the patient has heart
disease.

\hypertarget{methodology}{%
\section{Methodology}\label{methodology}}

For this investigation, code written in R is used. From this code, two
machine learning algorithms are applied to the data. The first, a RF
algorithm and the second, a SVM algorithm. To conduct these methods, the
data is split into training and testing data. The ratio used is 70:30,
respectively. This means that 70\% of the data is used for training and
the remaining 30\% is for testing the model. The data is split using
base R and the simple random sample method. This method is used as the
responses do not vary much, with a ratio of 5.6 to 4.4. The training
data is used to develop feature sets, train the selected algorithms,
tune hyper parameters, compare models etc. The test data is used to
estimate an unbiased assessment of the model's performance. For this
paper, the classification accuracy between the models is compared. The
classification accuracy measures the number of correct predictions made,
divided by the total number of predictions made. This evaluation method
is most popular for classification problems. The classification accuracy
is presented in the form of a confusion matrix. A confusion matrix is a
visual depiction of the correctly predicted responses, as well as the
incorrectly predicted responses.

\hypertarget{random-forests}{%
\subsection{Random Forests}\label{random-forests}}

The RF algorithm is a modification of the bagged decision trees, which
express better predictive performance. Using the randomForest package, a
RF model (RFM 1) is generated using the training data. Using the testing
data, a confusion matrix is presented. Although a RF model performs
well, there are hyper parameters that may be implemented when tuning the
model. To do this, the number of trees are adjusted, and the best
\(m_{try}\) value is applied to the model. The number of trees needs to
be large to stabilise the error rate. According to Boehmke and Greenwell
(2020), it is suggested that the model starts with 10 times the number
of features and in this case, there are 13 features. Starting with 10
times the number of features typically ensures the error estimate
converges. However, once other hyper parameters are adjusted, more or
less trees may be required. For the second RF model (RFM 2), the number
of trees is set to the default, and performs slightly better. The next
hyper parameter considered is \(m_{try}\). Once the best \(m_{try}\) is
computed, the value is inserted into the model. By doing this, the
classification accuracy of the model is slightly improved, which is
presented by the confusion matrix. Alternative methods of evaluating the
models performance to the classification accuracy is also consulted,
namely ROC curves as well as variable's importance. As a robustness
check, the RMSE (Root Mean Square Error) scores are calculated for the
RF models, and are compared to the classification accuracy.

\hypertarget{support-vector-machine}{%
\subsection{Support Vector Machine}\label{support-vector-machine}}

Using the Caret package, a SVM model (SVM 1) is generated. SVMs provide
a direct approach to binary classification. A SVM is a supervised
machine learning algorithm that is used to classify data into different
classes. This approach makes use of a hyperplane - which is a decision
boundary between the classes. Before training the data, the
traincontrol() is implemented. This allows the train() function to be
used under the caret package. The list returned by the traincontrol()
method is placed into the train() method. A confusion matrix is
presented, depicting the accuracy of this base model. Once this is done,
the model is fine tuned by assigning values to the penalty parameter of
the error term (C). This is the degree of correct classification that
the algorithm has to meet. Once again, the results are presented in the
form of a confusion matrix.

\hypertarget{results-and-discussion}{%
\section{Results and Discussion}\label{results-and-discussion}}

The next section of the paper presents the results of the data
manipulation and methods used. The results are presented as plots and
diagrams to better illustrate the outcomes. The classification
accuracies as well as the RMSE scores are found in the Appendix.

\hypertarget{random-forests-1}{%
\subsection{Random Forests}\label{random-forests-1}}

The figure below is a diagram of the confusion matrix for RFM 1. The
graph depicts that a notable percentage of the ``yes'' and ``no'' (1 and
0, respectively) values are correctly predicted.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-8-1} \end{center}
\newpage

Below is a graphical representation of the optimal number assigned to
\(m_{try}\). As this is a machine learning algorithm, each time the code
is run, a different optimal \(m_{try}\) may be revealed.

\begin{verbatim}
## mtry = 3  OOB error = 12.7% 
## Searching left ...
## mtry = 2     OOB error = 11.11% 
## 0.125 0.01 
## Searching right ...
## mtry = 4     OOB error = 11.9% 
## -0.07142857 0.01
\end{verbatim}

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-9-1} \end{center}

The confusion matrix of RFM 2 is depicted below. As shown in the
diagram, RFM 2 performs equally as well as RFM 1. The hyper parameters
did not impact the predictive power of the model.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-11-1} \end{center}

The ROC curves for the two RF models are presented below. Another way to
assess the strength of the RF models is to compare the area under the
ROC curves for each model. As the graphs depict, the area is similar,
indicating similar predictive power between RFM 1 and RFM 2.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-12-1} \end{center}

The variable importance of the two RF models are presented below. The
mean decrease accuracy provides an estimate of the loss in prediction
performance when that variable is omitted from the training dataset. In
the variable importance graph for RFM 1, the variable that indicates if
a patient has thalassemia is seen as the most important variable. For
RFM 2, the variable indicating the chest pain type is the most important
variable.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-13-1} \end{center}

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-14-1} \end{center}

Below is the confusion matrix for a third RF model (RFM 3). In this
model, the bottom three variables of the variable importance plots above
are omitted. As shown in the confusion matrix, this does slightly impact
the predictive power of the model. RFM 3 has the highest classification
accuracy, however, the model also has the highest RMSE score. The RMSE
score is below 0.5, showcasing that the model is still a somewhat
accurate predictor.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-16-1} \end{center}

\hypertarget{support-vector-machine-1}{%
\subsection{Support Vector Machine}\label{support-vector-machine-1}}

Below is the confusion matrix for the first SVM model, SVM 1. As the
figure depicts, the majority of the responses are correctly predicted.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-19-1} \end{center}

The graph below depicts the changes made to the C parameter of the SVM
model. Once this is applied to the model, there is no significant change
in the classification accuracy of the model.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-20-1} \end{center}

The figure below is the confusion matrix for the second SVM model, SVM
2. As the graph depicts, the model has predicted a majority of the
responses correctly.

\begin{center}\includegraphics{ML_project_files/figure-latex/unnamed-chunk-22-1} \end{center}

As the results of the investigation establish, the two machine learning
algorithms (RFs and SVMs) are both adequate predictive tools when
attempting to depict heart disease in patients in their base form as
well as after fine tuning. The classification accuracies of the
algorithms remain similar to one another before and after the addition
of hyper parameters.

\hypertarget{robustness-checks}{%
\section{Robustness Checks}\label{robustness-checks}}

Due to the similar results (namely the classification accuracy)
presented by the models, an attempt to assess the validity of the models
is implemented. To do this, a robustness check in which the dataset is
altered, is conducted. The binomial dependent variable in the data is
manually altered, whereby 56 values are changed. Once the changes are
made, the code is run. The outcomes show a classification accuracy of
around 50\% for both the RF and SVM models. This indicates that even
with a dataset with lower predictability, the models perform on a
similar level. As another robustness check, an alternative package for
RFs is used. In line with Boehmke \& Greenwell (2020), the ranger
package is applied. The results indicate that the RF models have RMSE
scores of between 3 and 4, with the latter being the lowest.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

In conclusion, this paper reveals that the SVM algorithm slightly
outperforms the RF algorithm when predicting the presence of heart
disease amongst patients. After the addition of hyper parameters for
both algorithms, the classification accuracies are not significantly
altered. As such, this indicates that the base models and the fine tuned
models possess similar predictive powers. It is important to note that
both algorithms, base as well as fine tuned of each, provide an
acceptable classification accuracy of above 70\%. After conducting
robustness checks, it is established that the outcomes of the algorithms
are reliable.

\newpage

\hypertarget{reference-list}{%
\section{Reference List}\label{reference-list}}

Boehmke, B. \& Greenwell, B. 2020. \emph{Hands-On Machine Learning with
R}. CRC Press

\newpage

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{classification-accuracies}{%
\subsection{Classification Accuracies}\label{classification-accuracies}}

\hypertarget{rfm-1}{%
\subsubsection{RFM 1:}\label{rfm-1}}

\begin{verbatim}
## [1] 0.7222222
\end{verbatim}

\hypertarget{rfm-2}{%
\subsubsection{RFM 2:}\label{rfm-2}}

\begin{verbatim}
## [1] 0.7222222
\end{verbatim}

\hypertarget{rfm-3}{%
\subsubsection{RFM 3}\label{rfm-3}}

\begin{verbatim}
## [1] 0.7592593
\end{verbatim}

\hypertarget{svm-1}{%
\subsubsection{SVM 1:}\label{svm-1}}

\begin{verbatim}
## [1] 0.7592593
\end{verbatim}

\hypertarget{svm-2}{%
\subsubsection{SVM 2:}\label{svm-2}}

\begin{verbatim}
## [1] 0.7407407
\end{verbatim}

\hypertarget{rfm-1-2-3-ranger-results}{%
\subsection{RFM 1, 2 \& 3: Ranger
Results}\label{rfm-1-2-3-ranger-results}}

\begin{verbatim}
## [1] 0.3563483
\end{verbatim}

\begin{verbatim}
## [1] 0.3779645
\end{verbatim}

\begin{verbatim}
## [1] 0.4454354
\end{verbatim}

\bibliography{Tex/ref}





\end{document}
