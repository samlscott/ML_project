\documentclass[11pt,preprint, authoryear]{elsarticle}

\usepackage{lmodern}
%%%% My spacing
\usepackage{setspace}
\setstretch{1.2}
\DeclareMathSizes{12}{14}{10}{10}

% Wrap around which gives all figures included the [H] command, or places it "here". This can be tedious to code in Rmarkdown.
\usepackage{float}
\let\origfigure\figure
\let\endorigfigure\endfigure
\renewenvironment{figure}[1][2] {
    \expandafter\origfigure\expandafter[H]
} {
    \endorigfigure
}

\let\origtable\table
\let\endorigtable\endtable
\renewenvironment{table}[1][2] {
    \expandafter\origtable\expandafter[H]
} {
    \endorigtable
}


\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi

\usepackage{amssymb, amsmath, amsthm, amsfonts}

\def\bibsection{\section*{References}} %%% Make "References" appear before bibliography


\usepackage[round]{natbib}

\usepackage{longtable}
\usepackage[margin=2.3cm,bottom=2cm,top=2.5cm, includefoot]{geometry}
\usepackage{fancyhdr}
\usepackage[bottom, hang, flushmargin]{footmisc}
\usepackage{graphicx}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\setlength{\parindent}{0cm}
\setlength{\parskip}{1.3ex plus 0.5ex minus 0.3ex}
\usepackage{textcomp}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.3pt}

\usepackage{array}
\newcolumntype{x}[1]{>{\centering\arraybackslash\hspace{0pt}}p{#1}}

%%%%  Remove the "preprint submitted to" part. Don't worry about this either, it just looks better without it:
\makeatletter
\def\ps@pprintTitle{%
  \let\@oddhead\@empty
  \let\@evenhead\@empty
  \let\@oddfoot\@empty
  \let\@evenfoot\@oddfoot
}
\makeatother

 \def\tightlist{} % This allows for subbullets!

\usepackage{hyperref}
\hypersetup{breaklinks=true,
            bookmarks=true,
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=blue,
            pdfborder={0 0 0}}


% The following packages allow huxtable to work:
\usepackage{siunitx}
\usepackage{multirow}
\usepackage{hhline}
\usepackage{calc}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{caption}


\newenvironment{columns}[1][]{}{}

\newenvironment{column}[1]{\begin{minipage}{#1}\ignorespaces}{%
\end{minipage}
\ifhmode\unskip\fi
\aftergroup\useignorespacesandallpars}

\def\useignorespacesandallpars#1\ignorespaces\fi{%
#1\fi\ignorespacesandallpars}

\makeatletter
\def\ignorespacesandallpars{%
  \@ifnextchar\par
    {\expandafter\ignorespacesandallpars\@gobble}%
    {}%
}
\makeatother

\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newenvironment{CSLReferences}%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  {\par}


\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}

%%% Include extra packages specified by user

%%% Hard setting column skips for reports - this ensures greater consistency and control over the length settings in the document.
%% page layout
%% paragraphs
\setlength{\baselineskip}{12pt plus 0pt minus 0pt}
\setlength{\parskip}{12pt plus 0pt minus 0pt}
\setlength{\parindent}{0pt plus 0pt minus 0pt}
%% floats
\setlength{\floatsep}{12pt plus 0 pt minus 0pt}
\setlength{\textfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\intextsep}{14pt plus 0pt minus 0pt}
\setlength{\dbltextfloatsep}{20pt plus 0pt minus 0pt}
\setlength{\dblfloatsep}{14pt plus 0pt minus 0pt}
%% maths
\setlength{\abovedisplayskip}{12pt plus 0pt minus 0pt}
\setlength{\belowdisplayskip}{12pt plus 0pt minus 0pt}
%% lists
\setlength{\topsep}{10pt plus 0pt minus 0pt}
\setlength{\partopsep}{3pt plus 0pt minus 0pt}
\setlength{\itemsep}{5pt plus 0pt minus 0pt}
\setlength{\labelsep}{8mm plus 0mm minus 0mm}
\setlength{\parsep}{\the\parskip}
\setlength{\listparindent}{\the\parindent}
%% verbatim
\setlength{\fboxsep}{5pt plus 0pt minus 0pt}



\begin{document}



\begin{frontmatter}  %

\title{Data Science: Machine Learning}

% Set to FALSE if wanting to remove title (for submission)




\author[Add1]{Samantha Scott}
\ead{20945043@sun.ac.za}





\address[Add1]{Stellenbosch University, Cape Town, South Africa}



\vspace{1cm}


\begin{keyword}
\footnotesize{
Machine Learning \sep Heart Disease Prediction \sep Random Forests \\
\vspace{0.3cm}
}
\end{keyword}



\vspace{0.5cm}

\end{frontmatter}


\newpage
\renewcommand{\contentsname}{Table of Contents}
{\tableofcontents}
\newpage

%________________________
% Header and Footers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{fancy}
\chead{}
\rhead{Predicting Heart Disease}
\lfoot{}
\rfoot{\footnotesize Page \thepage}
\lhead{}
%\rfoot{\footnotesize Page \thepage } % "e.g. Page 2"
\cfoot{}

%\setlength\headheight{30pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%________________________

\headsep 35pt % So that header does not go over title




\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

As Boehmke and Greenwell (2020) state, the Machine Learning process is
very iterative and heuristic-based. It is difficult to establish which
Machine Learnign method with perform best as a predictive tool, with
minimal knowledge of the problem or data at hand. This dilemma is known
as the no free lunch theorem. The aim of this paper is to predict heart
disease amongst patients, using be the performing predictive tool.

The investigation consists of a comparison between two Machine Learning
algorithms, namely Random Forests and Support Vector Machines, as
prediction tools. In order to assess the predictive powers of the
aforementioned methods, data on possible heart disease patients is used.
The process of using Machine Learning algorithms to predict heart
disease amongst patients has been broadly explored. This investigation
serves to contribute to this body of literature by comparing two
predominant Machine Learning algorithms. Ultimately, the results of this
paper indicate that both Random Forests as well as Support Vector
Machines showcase strong predictive powers, with a classification
accuracy of above 70\%. Further, the models do not gain predictive power
once being fine tuned, indicating that the basic model is sufficient
enough, given the data and problem.

The paper is structured as follows: section 2 provides an overview of
the research question as well the data used to solve the problem at
hand, section 3 provides information on the the methodology followed
when generating the Random Forest and Support Vector Machine models,
section 4 presents and discusses the results of the models, section 5
highlights the robustness checks implemented to verify the outcomes of
the models, and lastly, section 6 contains the concluding remarks of the
paper.

\hypertarget{research-question-and-data}{%
\section{Research Question and Data}\label{research-question-and-data}}

The main goal of the Machine Learning process is to find an algoritmn
that most accurately predicts future values based on a set of features.
This paper aims to establish which Machine Leaning algorithm performs
best when predicting whether a patient has heart disease, or not. The
problem at hand is expressed as a supervised binomial classification
problem. The data used in this investigation is heart disease data from
Kaggle and contains 180 observations. Kaggle is an online platform where
data scientists and machine learning practitioners can access datasets
as well as build portfolios. The benefit of obtaining data from this
source, is the usability score assigned to the dataset. This particular
dataset is assinged a higher usability score.

The data used contains a number of health related indicators. For this
investigation, the dependent variable is the presence of heart disease
in a patient. This variable is a binomial, yes or no, variable. Using
other indicators, such as age, whether a patient has a blood disorder
called thalassemia as well as the type of chest pain a patient is
experiencing, models are generated to predict if the patient has heart
disease.

\hypertarget{methodology}{%
\section{Methodology}\label{methodology}}

For this investigation, code written in R is used. From this code, two
Machine Learning algorithms are applied to the data. The first, a Random
Forest (RF) and the second, a Support Vector Machine (SVM). To conduct
these methods, the data is split into training and testing data. The
ratio used is 70:30, respectively. This means that 70\% of the data is
used for training and the remaining 30\% is for testing the model. The
data is split using base R and the simple random sample method. This
method is used as the responses do not vary much, with a ratio of 5.6 to
4.4. The training data is used to develop feature sets, train our
algorithmns, tune hyperparameters, compare models etc. The test data is
used to estimate an unbiased assessment of the model's performance. For
this paper, the classification accuracy between the models is compared.
The classification accuracy measures the number of correct predictions
made, divided by the total number of predictions made. This evaluation
method is the most popular one for classification problems.

\hypertarget{random-forests}{%
\subsection{Random Forests}\label{random-forests}}

The Random Forest algorithmn is a modification of the bagged decision
trees, which express better predictive performance. Using the
randomForest package, a Random Forest model (RFM 1) is generated using
the training data. Using the testing data, a condusion matirx is
presented. Although a Random Forest performs well, there are tunable
hyper parameters that may be implemented when tuning the model. To do
this, the number of trees are adjusted, and the best \(m_{try}\) value
is applied to the model. The number of trees needs to be large to
stabilise the error rate. According to Boehmke and Greenwell (2020), it
is suggested that the model starts with 10 times the number of features,
in this case, there are 13 features. However, once other hyper
parameters are adjusted, more or less trees may be required. For the
second Random Forest model, the number of trees is set to the default,
and performs slightly better. The next hyper parameter considered is
\(m_{try}\). Once the best \(m_{try}\) is computed, the value is
inserted into the model. By doing this, the classification accuracy of
the model is slightly improved, which is presented by the confusion
matrix. Alternative methods of evaluating the models performance to the
classification accuracy is also consulted, namely ROC curves as well as
variable's importance.

\newpage

\hypertarget{support-vector-machine}{%
\subsection{Support Vector Machine}\label{support-vector-machine}}

Using the Caret package, a Support Vector Machine model (SVM 1) is
generated. Support Vector Machines provide a direct approach to binary
classification. A Support Vector Machine is a supervised Machine
Learning algorithm which is used to classify data into different
classes. This approach makes use of a hyperplane - which is a decision
boundary between the classes. Before training the data, the
traincontrol() is implemented. This allows the train() function to be
used under the caret package. The list returned by the traincontrol()
method is placed into the train() method. A confusion matrix is
presented, depiced the accuracy of this base model. Once this is done,
the model is hyper parametised by assigning values to the penalty
parameter of the error term (C). This is the degree of correct
classification that the algorithmn has to meet. Once again, the results
are presented in the form of a confusion matrix

\newpage

\hypertarget{results-and-discussion}{%
\section{Results and Discussion}\label{results-and-discussion}}

The next section of the paper presents the results of the data
manipulation and methods used. The results are presented as plots and
diagrams, to better illustrate the outcomes.

\hypertarget{random-forests-1}{%
\subsection{Random Forests}\label{random-forests-1}}

The figure below is an illustration of the first Random Forest Model
(RFM 1). The number of trees selected for the first model is 130. As the
graph depicts, starting with 10 times the number of features typically
ensures the error estimate converges.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-7-1.pdf}
\newpage The figure below is a diagram of the confusion matrix for RFM
1. The graph depicts that a notable percentage of the ``yes'' and ``no''
(1 and 0, respectively) values are correctly predicted.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-8-1.pdf}
\newpage Below is a graphical representation of the optimal number
assigned to \(m_{try}\). As this is a Machine Learning algorithm, each
time the code is run, a different optimal \(m_{try}\) may be revealed.

\begin{verbatim}
## mtry = 3  OOB error = 12.7% 
## Searching left ...
## mtry = 2     OOB error = 11.11% 
## 0.125 0.01 
## Searching right ...
## mtry = 4     OOB error = 11.9% 
## -0.07142857 0.01
\end{verbatim}

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-9-1.pdf}
\newpage The graph below depicts the second Random Forest model, RFM 2.
In this model, the number of trees in increased to the default 500 and
the best \(m_{try}\) value is inserted into the function.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-10-1.pdf}
\newpage The confusion matrix of RFM 2 is depicted below. As shown in
the diagram, RFM 2 performs equally as well as RFM 1. The hyper
parameters did not impact the predictive power of the model.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-11-1.pdf}
\newpage The ROC curves for the two Random Forest models are presented
below. Another way to assess the strength of the Random Forest models is
to compare the area under the ROC curves for each model. As the graphs
depict, the area is similar, indicating similar predictive power between
RFM 1 and RFM 2. The red and blue curves indicate the ROC RFM 1 and 2
respectively.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-12-1.pdf}

\newpage

The variable importance of the two Random Forest models are presented
below. The mean decrease accuracy provides an estimate of the loss in
prediction performance when that variable is omitted from the training
dataset. For RFM 1, the variable that idicates if a patient has
thalassemia is seen as the most important variable. In the variable
importance graph for RFM 2, the variable indicating the chest pain type
is the most important variable.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-13-1.pdf}

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-14-1.pdf}
\newpage Below are the graphs for a third Random Forest model (RFM 3).
In this model, the bottom three variables of the variable importance
plots above are omitted. As shown in the confusion matrix below, this
does slightly impact the predictive power of the model. RFM 3 has the
highest classification accuracy, however, the model also has the highest
rmse score. The rmse score is below 0.5, showcasing that the model is
still a somewhat accurate predictor.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-16-1.pdf}

\newpage

\hypertarget{support-vector-machine-1}{%
\subsection{Support Vector Machine}\label{support-vector-machine-1}}

Below is the confusion matrix for the first Support Vector Machine
model, SVM 1. As the figure depicts, the majority of the responses are
correctly predicted.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-19-1.pdf}

\newpage

The graph below depicts the values assigned to the C parameter of the
Support Vector Machine model, the values range from 0 to 2.5. Once this
is applied to the model, there is no significant change in the
classification accuracy of the model.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-20-1.pdf}

\newpage

The figure below is the confusion matrix for the second Support Vector
Machine model, SVM 2. As the graph depicts, the model has predicted a
majority of the responses correctly.

\includegraphics{ML_project_files/figure-latex/unnamed-chunk-22-1.pdf}

As the results of the investigation establish, the two Machine Learning
algorithms (Random Forests and Support Vector Machines) are both
adequate predictive tools when attempting to depict heart disease in
patients in their base form as well as after fine tuning. The
classification accuracies of the algorithms remain similar to one
another before and after hyper parametising.

\newpage

\hypertarget{robustness-checks}{%
\section{Robustness Checks}\label{robustness-checks}}

Due to the similar results (namely the classification accuracy)
presented by the models, an attempt to assess the validity of the models
is implemented. To do this, a robustness check in which the dataset is
altered, is conducted. The binomial dependent variable in the data is
manually altered. Roughly, 50 values is changed. Once the changes are
made, the code is run. The outcomes show a classification accuracy of
around 50\% for both the Random Forest and Support Vector Machine
models. This indicates that with a dataset that is more difficult to
predict outcomes with, the models perform on a similar level. As another
robustness check, an alternative package for Random Forests is used. In
line with Boehmke \& Greenwell (2020), the ranger package is applied.
The results indicate that the Random Forest models have rmse scores of
between 3 and 4, with that of the second being the lowest.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

In conclusion, this paper reveals that Support Vector Machine model
slightly outperforms the Random Forest model when predicting the
presence of heart disease amongst patients. It is important to note that
both models, base as well as fine-tuned of each algorithmn, provides an
acceptable classification accuracy of above 70\%. After conducting
robustness checks, it is established that the outcomes of the models are
reliable.

\newpage

\hypertarget{reference-list}{%
\section{Reference List}\label{reference-list}}

Boehmke, B. \& Greenwell, B. 2020. \emph{Hands-On Machine Learning with
R}. CRC Press

\newpage

\hypertarget{appendix}{%
\section{Appendix}\label{appendix}}

\hypertarget{classification-accuracies}{%
\subsection{Classification Accuracies}\label{classification-accuracies}}

\hypertarget{rfm-1}{%
\subsubsection{RFM 1:}\label{rfm-1}}

\begin{verbatim}
## [1] 0.7222222
\end{verbatim}

\hypertarget{rfm-2}{%
\subsubsection{RFM 2:}\label{rfm-2}}

\begin{verbatim}
## [1] 0.7222222
\end{verbatim}

\hypertarget{rfm-3}{%
\subsubsection{RFM 3}\label{rfm-3}}

\begin{verbatim}
## [1] 0.7592593
\end{verbatim}

\hypertarget{svm-1}{%
\subsubsection{SVM 1:}\label{svm-1}}

\begin{verbatim}
## [1] 0.7592593
\end{verbatim}

\hypertarget{svm-2}{%
\subsubsection{SVM 2:}\label{svm-2}}

\begin{verbatim}
## [1] 0.7407407
\end{verbatim}

\hypertarget{rfm-1-2-3-ranger-results}{%
\subsection{RFM 1, 2 \& 3: Ranger
Results}\label{rfm-1-2-3-ranger-results}}

\begin{verbatim}
## [1] 0.3563483
\end{verbatim}

\begin{verbatim}
## [1] 0.3779645
\end{verbatim}

\begin{verbatim}
## [1] 0.4454354
\end{verbatim}

\bibliography{Tex/ref}





\end{document}
